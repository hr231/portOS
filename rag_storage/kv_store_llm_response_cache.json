{
  "default:extract:0aa8f67751fa25744eb2784429b04cb3": {
    "return": "entity<|#|>Harshit B.<|#|>Person<|#|>Harshit B. is an AI Engineer and ML Systems builder based in Boston, MA, with a Master of Science in Data Analytics Engineering from Northeastern University.\nentity<|#|>Northeastern University<|#|>Organization<|#|>Northeastern University is an educational institution where Harshit B. is pursuing his Master of Science in Data Analytics Engineering.\nentity<|#|>LDRP Institute of Technology and Research<|#|>Organization<|#|>LDRP Institute of Technology and Research is an educational institution in Gandhinagar, India, where Harshit B. earned his Bachelor of Engineering in Computer Engineering.\nentity<|#|>Boston<|#|>Location<|#|>Boston is the city where Harshit B. is based.\nentity<|#|>Staples Inc.<|#|>Organization<|#|>Staples Inc. is a company where Harshit B. worked as an AI Engineer Intern.\nentity<|#|>Pixeltechnologies<|#|>Organization<|#|>Pixeltechnologies is a company where Harshit B. worked as an ML Engineer Intern.\nentity<|#|>GROWITUP<|#|>Organization<|#|>GROWITUP is a company where Harshit B. worked as a Data Analyst Intern.\nentity<|#|>FrontShiftAI<|#|>Artifact<|#|>FrontShiftAI is a multi-tenant agentic platform developed by Harshit B.\nentity<|#|>Credit Risk Forecasting via Temporal Architectures<|#|>Artifact<|#|>Credit Risk Forecasting via Temporal Architectures is a project developed by Harshit B. for credit risk forecasting.\nentity<|#|>GEMTREK<|#|>Artifact<|#|>GEMTREK is a diamond manufacturing analytics system developed by Harshit B.\nentity<|#|>FastAPI<|#|>Artifact<|#|>FastAPI is a technology used by Harshit B. in his projects.\nentity<|#|>Airflow<|#|>Artifact<|#|>Airflow is a technology used by Harshit B. in his projects.\nentity<|#|>ChromaDB<|#|>Artifact<|#|>ChromaDB is a vector database used by Harshit B. in his projects.\nentity<|#|>Modal<|#|>Artifact<|#|>Modal is a technology used by Harshit B. in his projects.\nentity<|#|>LiveKit<|#|>Artifact<|#|>LiveKit is a technology used by Harshit B. in his projects.\nentity<|#|>React<|#|>Artifact<|#|>React is a technology used by Harshit B. in his projects.\nentity<|#|>TensorFlow<|#|>Artifact<|#|>TensorFlow is a technology used by Harshit B. in his projects.\nentity<|#|>SHAP<|#|>Artifact<|#|>SHAP is a technology used by Harshit B. in his projects.\nentity<|#|>Azure<|#|>Artifact<|#|>Azure is a cloud platform used by Harshit B. in his projects.\nentity<|#|>SQL<|#|>Artifact<|#|>SQL is a language used by Harshit B. in his projects.\nentity<|#|>Python<|#|>Artifact<|#|>Python is a language used by Harshit B. in his projects.\nrelation<|#|>Harshit B.<|#|>Northeastern University<|#|>education, affiliation<|#|>Harshit B. is affiliated with Northeastern University as a student.\nrelation<|#|>Harshit B.<|#|>Staples Inc.<|#|>work experience, AI engineering<|#|>Harshit B. worked as an AI Engineer Intern at Staples Inc.\nrelation<|#|>Harshit B.<|#|>Pixeltechnologies<|#|>work experience, ML engineering<|#|>Harshit B. worked as an ML Engineer Intern at Pixeltechnologies.\nrelation<|#|>Harshit B.<|#|>GROWITUP<|#|>work experience, data analysis<|#|>Harshit B. worked as a Data Analyst Intern at GROWITUP.\nrelation<|#|>Harshit B.<|#|>FrontShiftAI<|#|>project development, AI engineering<|#|>Harshit B. developed the FrontShiftAI project.\nrelation<|#|>Harshit B.<|#|>Credit Risk Forecasting via Temporal Architectures<|#|>project development, credit risk forecasting<|#|>Harshit B. developed the Credit Risk Forecasting via Temporal Architectures project.\nrelation<|#|>Harshit B.<|#|>GEMTREK<|#|>project development, diamond manufacturing analytics<|#|>Harshit B. developed the GEMTREK project.\nrelation<|#|>FrontShiftAI<|#|>FastAPI<|#|>technology usage, project development<|#|>FrontShiftAI uses FastAPI as a technology.\nrelation<|#|>FrontShiftAI<|#|>Airflow<|#|>technology usage, project development<|#|>FrontShiftAI uses Airflow as a technology.\nrelation<|#|>Credit Risk Forecasting via Temporal Architectures<|#|>TensorFlow<|#|>technology usage, project development<|#|>Credit Risk Forecasting via Temporal Architectures uses TensorFlow as a technology.\nrelation<|#|>GEMTREK<|#|>SQL<|#|>technology usage, project development<|#|>GEMTREK uses SQL as a technology.\n<|COMPLETE|>",
    "cache_type": "extract",
    "chunk_id": "chunk-2591ccd2ed85a8b0b0d728c37788cbe3",
    "original_prompt": "---Task---\nExtract entities and relationships from the input text in Data to be Processed below.\n\n---Instructions---\n1.  **Strict Adherence to Format:** Strictly adhere to all format requirements for entity and relationship lists, including output order, field delimiters, and proper noun handling, as specified in the system prompt.\n2.  **Output Content Only:** Output *only* the extracted list of entities and relationships. Do not include any introductory or concluding remarks, explanations, or additional text before or after the list.\n3.  **Completion Signal:** Output `<|COMPLETE|>` as the final line after all relevant entities and relationships have been extracted and presented.\n4.  **Output Language:** Ensure the output language is English. Proper nouns (e.g., personal names, place names, organization names) must be kept in their original language and not translated.\n\n---Data to be Processed---\n<Entity_types>\n[Person,Creature,Organization,Location,Event,Concept,Method,Content,Data,Artifact,NaturalObject]\n\n<Input Text>\n```\n# Harshit B. — Portfolio\n\n## About\n\nHarshit B. is an AI Engineer and ML Systems builder based in Boston, MA. He is pursuing a Master of Science in Data Analytics Engineering at Northeastern University (GPA: 3.9/4.0, expected December 2026). He holds a Bachelor of Engineering in Computer Engineering from LDRP Institute of Technology and Research, Gandhinagar, India (GPA: 3.3/4.0, May 2024).\n\nHe builds production ML systems — agentic AI platforms, temporal risk models, real-time voice agents, and scalable data pipelines. He cares about systems that work at scale, not just in notebooks.\n\nContact: brahmbhatt.h@northeastern.edu | 857-565-4643 | Boston, MA | LinkedIn: linkedin.com/in/harshitb1611\n\n## Certifications\n\n- Stanford Machine Learning\n- DeepLearning.AI Generative AI\n- UPenn Quantitative Modeling\n\n---\n\n## Work Experience\n\n### AI Engineer Intern — Staples Inc. (Jan 2026 – Present, Framingham, MA)\n\n- Spearheaded production-grade LLM applications automating high-labor workflows, reducing manual effort by 40% and error rates across enterprise retail operations.\n- Constructed LangGraph-based inference pipelines with FastAPI, GraphQL, and gRPC integrations for real-time reasoning and retrieval over PGVector and Neo4j.\n- Integrated OpenAI, Anthropic, Ollama, and vLLM backends through unified connector APIs, enabling rapid experimentation and model portability.\n- Optimized Kubernetes-deployed vLLM clusters for low latency and high throughput via dynamic batching, quantization, and GPU utilization tuning.\n\n### ML Engineer Intern — Pixeltechnologies (Jan – Jul 2024, Remote)\n\n- Architected Python-based prediction pipelines using scikit-learn and XGBoost to forecast ad engagement on 100K+ events; enhanced campaign ROI by 22%.\n- Engineered SQL-driven ETL and Airflow DAGs to process high-velocity A/B test logs; cut model retraining latency by 40%.\n- Operationalized ML explainability by deploying interpretable models with SHAP values; uncovered 3 key vulnerabilities and improved accuracy by 18%.\n\n### Data Analyst Intern — GROWITUP (Jul 2023 – Jan 2024, Remote)\n\n- Pioneered a vectorized search system using OpenAI embeddings and FastAPI, achieving 96% faster retrieval across 5K+ documents.\n- Modeled user sessions with Snowflake and PostgreSQL to detect behavioral anomalies and data drift patterns.\n\n---\n\n## Projects\n\n### FrontShiftAI: Multi-Tenant Agentic Platform (Sept 2025)\nTechnologies: FastAPI, Airflow, ChromaDB, Modal, LiveKit, React\n\n- Designed a Unified Agent Router in FastAPI using regex-based intent detection with LLM fallback to intelligently route requests between deterministic SQL agents and probabilistic LLaMA-3 RAG pipelines.\n- Automated Airflow 3.0 ETL pipelines utilizing a dedicated SmolVLM Vision Microservice to ingest unstructured PDF data, validating quality via Great Expectations before embedding into vector databases.\n- Implemented Hybrid Search (BM25 + Vector) with Cross-Encoder Reranking, significantly reducing hallucination rates for policy queries.\n- Deployed a serverless voice agent on Modal via LiveKit WebRTC for bi-directional real-time audio interactions.\n\n### Credit Risk Forecasting via Temporal Architectures (Apr 2025)\nTechnologies: TensorFlow, SHAP, Azure CI/CD, SQL\n\n- Segmented 30K+ financial transactions into lag-aware bins and extracted temporal features to surface default patterns.\n- Trained Bi-LSTM and TabTransformer models for risk classification; boosted minority F1-score by 16% achieving 81.9% accuracy.\n- Visualized temporal risk triggers using SHAP plots to improve auditor interpretability and model trust.\n- Azure DevOps CI/CD pipelines for reproducible deployment.\n\n### GEMTREK: Diamond Manufacturing Analytics System (Dec 2024)\nTechnologies: SQL, Python, Power BI, Snowflake, Azure\n\n- Optimized Snowflake ETL pipelines (35% faster processing).\n- Python analytics on 100K+ records for diamond manufacturing operations.\n- Real-time Power BI dashboards via REST API — 40% better operational transparency.\n\n---\n\n## Technical Skills\n\n- **Languages:** Python, C++, SQL, Shell Scripting, JavaScript\n- **AI/ML/DL:** Scikit-learn, XGBoost, TensorFlow, PyTorch, Hugging Face, SHAP, Model Training & Fine-Tuning\n- **LLM & Gen AI:** OpenAI API, LangChain, LangGraph, vLLM, RAG Pipelines, Agentic Frameworks, Tool-Calling\n- **Vector Databases:** ChromaDB, Pinecone, PGVector, Neo4j, Hybrid Search (BM25 + Vector)\n- **Data Pipelines & MLOps:** Apache Airflow, FastAPI, Docker, Kubernetes, CI/CD (Azure, GitHub), Model Monitoring\n- **Cloud & Infrastructure:** GCP (GKE, Cloud SQL), AWS S3, Snowflake, PostgreSQL, Azure Databricks\n```\n\n<Output>\n---Role---\nYou are a Knowledge Graph Specialist responsible for extracting entities and relationships from the input text.\n\n---Instructions---\n1.  **Entity Extraction & Output:**\n    *   **Identification:** Identify clearly defined and meaningful entities in the input text.\n    *   **Entity Details:** For each identified entity, extract the following information:\n        *   `entity_name`: The name of the entity. If the entity name is case-insensitive, capitalize the first letter of each significant word (title case). Ensure **consistent naming** across the entire extraction process.\n        *   `entity_type`: Categorize the entity using one of the following types: `Person,Creature,Organization,Location,Event,Concept,Method,Content,Data,Artifact,NaturalObject`. If none of the provided entity types apply, do not add new entity type and classify it as `Other`.\n        *   `entity_description`: Provide a concise yet comprehensive description of the entity's attributes and activities, based *solely* on the information present in the input text.\n    *   **Output Format - Entities:** Output a total of 4 fields for each entity, delimited by `<|#|>`, on a single line. The first field *must* be the literal string `entity`.\n        *   Format: `entity<|#|>entity_name<|#|>entity_type<|#|>entity_description`\n\n2.  **Relationship Extraction & Output:**\n    *   **Identification:** Identify direct, clearly stated, and meaningful relationships between previously extracted entities.\n    *   **N-ary Relationship Decomposition:** If a single statement describes a relationship involving more than two entities (an N-ary relationship), decompose it into multiple binary (two-entity) relationship pairs for separate description.\n        *   **Example:** For \"Alice, Bob, and Carol collaborated on Project X,\" extract binary relationships such as \"Alice collaborated with Project X,\" \"Bob collaborated with Project X,\" and \"Carol collaborated with Project X,\" or \"Alice collaborated with Bob,\" based on the most reasonable binary interpretations.\n    *   **Relationship Details:** For each binary relationship, extract the following fields:\n        *   `source_entity`: The name of the source entity. Ensure **consistent naming** with entity extraction. Capitalize the first letter of each significant word (title case) if the name is case-insensitive.\n        *   `target_entity`: The name of the target entity. Ensure **consistent naming** with entity extraction. Capitalize the first letter of each significant word (title case) if the name is case-insensitive.\n        *   `relationship_keywords`: One or more high-level keywords summarizing the overarching nature, concepts, or themes of the relationship. Multiple keywords within this field must be separated by a comma `,`. **DO NOT use `<|#|>` for separating multiple keywords within this field.**\n        *   `relationship_description`: A concise explanation of the nature of the relationship between the source and target entities, providing a clear rationale for their connection.\n    *   **Output Format - Relationships:** Output a total of 5 fields for each relationship, delimited by `<|#|>`, on a single line. The first field *must* be the literal string `relation`.\n        *   Format: `relation<|#|>source_entity<|#|>target_entity<|#|>relationship_keywords<|#|>relationship_description`\n\n3.  **Delimiter Usage Protocol:**\n    *   The `<|#|>` is a complete, atomic marker and **must not be filled with content**. It serves strictly as a field separator.\n    *   **Incorrect Example:** `entity<|#|>Tokyo<|location|>Tokyo is the capital of Japan.`\n    *   **Correct Example:** `entity<|#|>Tokyo<|#|>location<|#|>Tokyo is the capital of Japan.`\n\n4.  **Relationship Direction & Duplication:**\n    *   Treat all relationships as **undirected** unless explicitly stated otherwise. Swapping the source and target entities for an undirected relationship does not constitute a new relationship.\n    *   Avoid outputting duplicate relationships.\n\n5.  **Output Order & Prioritization:**\n    *   Output all extracted entities first, followed by all extracted relationships.\n    *   Within the list of relationships, prioritize and output those relationships that are **most significant** to the core meaning of the input text first.\n\n6.  **Context & Objectivity:**\n    *   Ensure all entity names and descriptions are written in the **third person**.\n    *   Explicitly name the subject or object; **avoid using pronouns** such as `this article`, `this paper`, `our company`, `I`, `you`, and `he/she`.\n\n7.  **Language & Proper Nouns:**\n    *   The entire output (entity names, keywords, and descriptions) must be written in `English`.\n    *   Proper nouns (e.g., personal names, place names, organization names) should be retained in their original language if a proper, widely accepted translation is not available or would cause ambiguity.\n\n8.  **Completion Signal:** Output the literal string `<|COMPLETE|>` only after all entities and relationships, following all criteria, have been completely extracted and outputted.\n\n---Examples---\n<Entity_types>\n[\"Person\",\"Creature\",\"Organization\",\"Location\",\"Event\",\"Concept\",\"Method\",\"Content\",\"Data\",\"Artifact\",\"NaturalObject\"]\n\n<Input Text>\n```\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor's authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan's shared commitment to discovery was an unspoken rebellion against Cruz's narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. \"If this tech can be understood...\" Taylor said, their voice quieter, \"It could change the game for us. For all of us.\"\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor's, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n```\n\n<Output>\nentity<|#|>Alex<|#|>person<|#|>Alex is a character who experiences frustration and is observant of the dynamics among other characters.\nentity<|#|>Taylor<|#|>person<|#|>Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\nentity<|#|>Jordan<|#|>person<|#|>Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\nentity<|#|>Cruz<|#|>person<|#|>Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\nentity<|#|>The Device<|#|>equipment<|#|>The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\nrelation<|#|>Alex<|#|>Taylor<|#|>power dynamics, observation<|#|>Alex observes Taylor's authoritarian behavior and notes changes in Taylor's attitude toward the device.\nrelation<|#|>Alex<|#|>Jordan<|#|>shared goals, rebellion<|#|>Alex and Jordan share a commitment to discovery, which contrasts with Cruz's vision.)\nrelation<|#|>Taylor<|#|>Jordan<|#|>conflict resolution, mutual respect<|#|>Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\nrelation<|#|>Jordan<|#|>Cruz<|#|>ideological conflict, rebellion<|#|>Jordan's commitment to discovery is in rebellion against Cruz's vision of control and order.\nrelation<|#|>Taylor<|#|>The Device<|#|>reverence, technological significance<|#|>Taylor shows reverence towards the device, indicating its importance and potential impact.\n<|COMPLETE|>\n\n\n<Entity_types>\n[\"Person\",\"Creature\",\"Organization\",\"Location\",\"Event\",\"Concept\",\"Method\",\"Content\",\"Data\",\"Artifact\",\"NaturalObject\"]\n\n<Input Text>\n```\nStock markets faced a sharp downturn today as tech giants saw significant declines, with the global tech index dropping by 3.4% in midday trading. Analysts attribute the selloff to investor concerns over rising interest rates and regulatory uncertainty.\n\nAmong the hardest hit, nexon technologies saw its stock plummet by 7.8% after reporting lower-than-expected quarterly earnings. In contrast, Omega Energy posted a modest 2.1% gain, driven by rising oil prices.\n\nMeanwhile, commodity markets reflected a mixed sentiment. Gold futures rose by 1.5%, reaching $2,080 per ounce, as investors sought safe-haven assets. Crude oil prices continued their rally, climbing to $87.60 per barrel, supported by supply constraints and strong demand.\n\nFinancial experts are closely watching the Federal Reserve's next move, as speculation grows over potential rate hikes. The upcoming policy announcement is expected to influence investor confidence and overall market stability.\n```\n\n<Output>\nentity<|#|>Global Tech Index<|#|>category<|#|>The Global Tech Index tracks the performance of major technology stocks and experienced a 3.4% decline today.\nentity<|#|>Nexon Technologies<|#|>organization<|#|>Nexon Technologies is a tech company that saw its stock decline by 7.8% after disappointing earnings.\nentity<|#|>Omega Energy<|#|>organization<|#|>Omega Energy is an energy company that gained 2.1% in stock value due to rising oil prices.\nentity<|#|>Gold Futures<|#|>product<|#|>Gold futures rose by 1.5%, indicating increased investor interest in safe-haven assets.\nentity<|#|>Crude Oil<|#|>product<|#|>Crude oil prices rose to $87.60 per barrel due to supply constraints and strong demand.\nentity<|#|>Market Selloff<|#|>category<|#|>Market selloff refers to the significant decline in stock values due to investor concerns over interest rates and regulations.\nentity<|#|>Federal Reserve Policy Announcement<|#|>category<|#|>The Federal Reserve's upcoming policy announcement is expected to impact investor confidence and market stability.\nentity<|#|>3.4% Decline<|#|>category<|#|>The Global Tech Index experienced a 3.4% decline in midday trading.\nrelation<|#|>Global Tech Index<|#|>Market Selloff<|#|>market performance, investor sentiment<|#|>The decline in the Global Tech Index is part of the broader market selloff driven by investor concerns.\nrelation<|#|>Nexon Technologies<|#|>Global Tech Index<|#|>company impact, index movement<|#|>Nexon Technologies' stock decline contributed to the overall drop in the Global Tech Index.\nrelation<|#|>Gold Futures<|#|>Market Selloff<|#|>market reaction, safe-haven investment<|#|>Gold prices rose as investors sought safe-haven assets during the market selloff.\nrelation<|#|>Federal Reserve Policy Announcement<|#|>Market Selloff<|#|>interest rate impact, financial regulation<|#|>Speculation over Federal Reserve policy changes contributed to market volatility and investor selloff.\n<|COMPLETE|>\n\n\n<Entity_types>\n[\"Person\",\"Creature\",\"Organization\",\"Location\",\"Event\",\"Concept\",\"Method\",\"Content\",\"Data\",\"Artifact\",\"NaturalObject\"]\n\n<Input Text>\n```\nAt the World Athletics Championship in Tokyo, Noah Carter broke the 100m sprint record using cutting-edge carbon-fiber spikes.\n```\n\n<Output>\nentity<|#|>World Athletics Championship<|#|>event<|#|>The World Athletics Championship is a global sports competition featuring top athletes in track and field.\nentity<|#|>Tokyo<|#|>location<|#|>Tokyo is the host city of the World Athletics Championship.\nentity<|#|>Noah Carter<|#|>person<|#|>Noah Carter is a sprinter who set a new record in the 100m sprint at the World Athletics Championship.\nentity<|#|>100m Sprint Record<|#|>category<|#|>The 100m sprint record is a benchmark in athletics, recently broken by Noah Carter.\nentity<|#|>Carbon-Fiber Spikes<|#|>equipment<|#|>Carbon-fiber spikes are advanced sprinting shoes that provide enhanced speed and traction.\nentity<|#|>World Athletics Federation<|#|>organization<|#|>The World Athletics Federation is the governing body overseeing the World Athletics Championship and record validations.\nrelation<|#|>World Athletics Championship<|#|>Tokyo<|#|>event location, international competition<|#|>The World Athletics Championship is being hosted in Tokyo.\nrelation<|#|>Noah Carter<|#|>100m Sprint Record<|#|>athlete achievement, record-breaking<|#|>Noah Carter set a new 100m sprint record at the championship.\nrelation<|#|>Noah Carter<|#|>Carbon-Fiber Spikes<|#|>athletic equipment, performance boost<|#|>Noah Carter used carbon-fiber spikes to enhance performance during the race.\nrelation<|#|>Noah Carter<|#|>World Athletics Championship<|#|>athlete participation, competition<|#|>Noah Carter is competing at the World Athletics Championship.\n<|COMPLETE|>",
    "queryparam": null,
    "create_time": 1771210913,
    "update_time": 1771210913,
    "_id": "default:extract:0aa8f67751fa25744eb2784429b04cb3"
  },
  "default:extract:018f378f3de25ce83a9649cd088ef464": {
    "return": "entity<|#|>LDRP Institute of Technology and Research, Gandhinagar, India<|#|>Location<|#|>LDRP Institute of Technology and Research is located in Gandhinagar, India, and is Harshit B.'s alma mater.\nentity<|#|>Framingham<|#|>Location<|#|>Framingham is a location where Harshit B. worked as an AI Engineer Intern at Staples Inc.\nentity<|#|>Gandhinagar<|#|>Location<|#|>Gandhinagar is a location in India where LDRP Institute of Technology and Research is situated.\nentity<|#|>Master of Science in Data Analytics Engineering<|#|>Concept<|#|>Master of Science in Data Analytics Engineering is a degree program Harshit B. is pursuing at Northeastern University.\nentity<|#|>Bachelor of Engineering in Computer Engineering<|#|>Concept<|#|>Bachelor of Engineering in Computer Engineering is a degree Harshit B. earned from LDRP Institute of Technology and Research.\nentity<|#|>AI Engineer Intern<|#|>Concept<|#|>AI Engineer Intern is a role Harshit B. held at Staples Inc.\nentity<|#|>ML Engineer Intern<|#|>Concept<|#|>ML Engineer Intern is a role Harshit B. held at Pixeltechnologies.\nentity<|#|>Data Analyst Intern<|#|>Concept<|#|>Data Analyst Intern is a role Harshit B. held at GROWITUP.\nentity<|#|>Stanford Machine Learning<|#|>Concept<|#|>Stanford Machine Learning is a certification or course related to machine learning.\nentity<|#|>DeepLearning.AI Generative AI<|#|>Concept<|#|>DeepLearning.AI Generative AI is a certification or course related to generative AI.\nentity<|#|>UPenn Quantitative Modeling<|#|>Concept<|#|>UPenn Quantitative Modeling is a certification or course related to quantitative modeling.\nrelation<|#|>Harshit B.<|#|>LDRP Institute of Technology and Research, Gandhinagar, India<|#|>education, affiliation<|#|>Harshit B. is affiliated with LDRP Institute of Technology and Research as an alumnus.\nrelation<|#|>Harshit B.<|#|>Master of Science in Data Analytics Engineering<|#|>education, degree program<|#|>Harshit B. is pursuing a Master of Science in Data Analytics Engineering.\nrelation<|#|>Harshit B.<|#|>Bachelor of Engineering in Computer Engineering<|#|>education, degree<|#|>Harshit B. earned a Bachelor of Engineering in Computer Engineering.\nrelation<|#|>Staples Inc.<|#|>Framingham<|#|>location, company<|#|>Staples Inc. is located in Framingham.\nrelation<|#|>Harshit B.<|#|>AI Engineer Intern<|#|>work experience, role<|#|>Harshit B. worked as an AI Engineer Intern.\nrelation<|#|>Harshit B.<|#|>ML Engineer Intern<|#|>work experience, role<|#|>Harshit B. worked as an ML Engineer Intern.\nrelation<|#|>Harshit B.<|#|>Data Analyst Intern<|#|>work experience, role<|#|>Harshit B. worked as a Data Analyst Intern.\nrelation<|#|>Harshit B.<|#|>Stanford Machine Learning<|#|>certification, education<|#|>Harshit B. is certified in Stanford Machine Learning.\nrelation<|#|>Harshit B.<|#|>DeepLearning.AI Generative AI<|#|>certification, education<|#|>Harshit B. is certified in DeepLearning.AI Generative AI.\nrelation<|#|>Harshit B.<|#|>UPenn Quantitative Modeling<|#|>certification, education<|#|>Harshit B. is certified in UPenn Quantitative Modeling.\n<|COMPLETE|>",
    "cache_type": "extract",
    "chunk_id": "chunk-2591ccd2ed85a8b0b0d728c37788cbe3",
    "original_prompt": "---Task---\nBased on the last extraction task, identify and extract any **missed or incorrectly formatted** entities and relationships from the input text.\n\n---Instructions---\n1.  **Strict Adherence to System Format:** Strictly adhere to all format requirements for entity and relationship lists, including output order, field delimiters, and proper noun handling, as specified in the system instructions.\n2.  **Focus on Corrections/Additions:**\n    *   **Do NOT** re-output entities and relationships that were **correctly and fully** extracted in the last task.\n    *   If an entity or relationship was **missed** in the last task, extract and output it now according to the system format.\n    *   If an entity or relationship was **truncated, had missing fields, or was otherwise incorrectly formatted** in the last task, re-output the *corrected and complete* version in the specified format.\n3.  **Output Format - Entities:** Output a total of 4 fields for each entity, delimited by `<|#|>`, on a single line. The first field *must* be the literal string `entity`.\n4.  **Output Format - Relationships:** Output a total of 5 fields for each relationship, delimited by `<|#|>`, on a single line. The first field *must* be the literal string `relation`.\n5.  **Output Content Only:** Output *only* the extracted list of entities and relationships. Do not include any introductory or concluding remarks, explanations, or additional text before or after the list.\n6.  **Completion Signal:** Output `<|COMPLETE|>` as the final line after all relevant missing or corrected entities and relationships have been extracted and presented.\n7.  **Output Language:** Ensure the output language is English. Proper nouns (e.g., personal names, place names, organization names) must be kept in their original language and not translated.\n\n<Output>\n---Role---\nYou are a Knowledge Graph Specialist responsible for extracting entities and relationships from the input text.\n\n---Instructions---\n1.  **Entity Extraction & Output:**\n    *   **Identification:** Identify clearly defined and meaningful entities in the input text.\n    *   **Entity Details:** For each identified entity, extract the following information:\n        *   `entity_name`: The name of the entity. If the entity name is case-insensitive, capitalize the first letter of each significant word (title case). Ensure **consistent naming** across the entire extraction process.\n        *   `entity_type`: Categorize the entity using one of the following types: `Person,Creature,Organization,Location,Event,Concept,Method,Content,Data,Artifact,NaturalObject`. If none of the provided entity types apply, do not add new entity type and classify it as `Other`.\n        *   `entity_description`: Provide a concise yet comprehensive description of the entity's attributes and activities, based *solely* on the information present in the input text.\n    *   **Output Format - Entities:** Output a total of 4 fields for each entity, delimited by `<|#|>`, on a single line. The first field *must* be the literal string `entity`.\n        *   Format: `entity<|#|>entity_name<|#|>entity_type<|#|>entity_description`\n\n2.  **Relationship Extraction & Output:**\n    *   **Identification:** Identify direct, clearly stated, and meaningful relationships between previously extracted entities.\n    *   **N-ary Relationship Decomposition:** If a single statement describes a relationship involving more than two entities (an N-ary relationship), decompose it into multiple binary (two-entity) relationship pairs for separate description.\n        *   **Example:** For \"Alice, Bob, and Carol collaborated on Project X,\" extract binary relationships such as \"Alice collaborated with Project X,\" \"Bob collaborated with Project X,\" and \"Carol collaborated with Project X,\" or \"Alice collaborated with Bob,\" based on the most reasonable binary interpretations.\n    *   **Relationship Details:** For each binary relationship, extract the following fields:\n        *   `source_entity`: The name of the source entity. Ensure **consistent naming** with entity extraction. Capitalize the first letter of each significant word (title case) if the name is case-insensitive.\n        *   `target_entity`: The name of the target entity. Ensure **consistent naming** with entity extraction. Capitalize the first letter of each significant word (title case) if the name is case-insensitive.\n        *   `relationship_keywords`: One or more high-level keywords summarizing the overarching nature, concepts, or themes of the relationship. Multiple keywords within this field must be separated by a comma `,`. **DO NOT use `<|#|>` for separating multiple keywords within this field.**\n        *   `relationship_description`: A concise explanation of the nature of the relationship between the source and target entities, providing a clear rationale for their connection.\n    *   **Output Format - Relationships:** Output a total of 5 fields for each relationship, delimited by `<|#|>`, on a single line. The first field *must* be the literal string `relation`.\n        *   Format: `relation<|#|>source_entity<|#|>target_entity<|#|>relationship_keywords<|#|>relationship_description`\n\n3.  **Delimiter Usage Protocol:**\n    *   The `<|#|>` is a complete, atomic marker and **must not be filled with content**. It serves strictly as a field separator.\n    *   **Incorrect Example:** `entity<|#|>Tokyo<|location|>Tokyo is the capital of Japan.`\n    *   **Correct Example:** `entity<|#|>Tokyo<|#|>location<|#|>Tokyo is the capital of Japan.`\n\n4.  **Relationship Direction & Duplication:**\n    *   Treat all relationships as **undirected** unless explicitly stated otherwise. Swapping the source and target entities for an undirected relationship does not constitute a new relationship.\n    *   Avoid outputting duplicate relationships.\n\n5.  **Output Order & Prioritization:**\n    *   Output all extracted entities first, followed by all extracted relationships.\n    *   Within the list of relationships, prioritize and output those relationships that are **most significant** to the core meaning of the input text first.\n\n6.  **Context & Objectivity:**\n    *   Ensure all entity names and descriptions are written in the **third person**.\n    *   Explicitly name the subject or object; **avoid using pronouns** such as `this article`, `this paper`, `our company`, `I`, `you`, and `he/she`.\n\n7.  **Language & Proper Nouns:**\n    *   The entire output (entity names, keywords, and descriptions) must be written in `English`.\n    *   Proper nouns (e.g., personal names, place names, organization names) should be retained in their original language if a proper, widely accepted translation is not available or would cause ambiguity.\n\n8.  **Completion Signal:** Output the literal string `<|COMPLETE|>` only after all entities and relationships, following all criteria, have been completely extracted and outputted.\n\n---Examples---\n<Entity_types>\n[\"Person\",\"Creature\",\"Organization\",\"Location\",\"Event\",\"Concept\",\"Method\",\"Content\",\"Data\",\"Artifact\",\"NaturalObject\"]\n\n<Input Text>\n```\nwhile Alex clenched his jaw, the buzz of frustration dull against the backdrop of Taylor's authoritarian certainty. It was this competitive undercurrent that kept him alert, the sense that his and Jordan's shared commitment to discovery was an unspoken rebellion against Cruz's narrowing vision of control and order.\n\nThen Taylor did something unexpected. They paused beside Jordan and, for a moment, observed the device with something akin to reverence. \"If this tech can be understood...\" Taylor said, their voice quieter, \"It could change the game for us. For all of us.\"\n\nThe underlying dismissal earlier seemed to falter, replaced by a glimpse of reluctant respect for the gravity of what lay in their hands. Jordan looked up, and for a fleeting heartbeat, their eyes locked with Taylor's, a wordless clash of wills softening into an uneasy truce.\n\nIt was a small transformation, barely perceptible, but one that Alex noted with an inward nod. They had all been brought here by different paths\n```\n\n<Output>\nentity<|#|>Alex<|#|>person<|#|>Alex is a character who experiences frustration and is observant of the dynamics among other characters.\nentity<|#|>Taylor<|#|>person<|#|>Taylor is portrayed with authoritarian certainty and shows a moment of reverence towards a device, indicating a change in perspective.\nentity<|#|>Jordan<|#|>person<|#|>Jordan shares a commitment to discovery and has a significant interaction with Taylor regarding a device.\nentity<|#|>Cruz<|#|>person<|#|>Cruz is associated with a vision of control and order, influencing the dynamics among other characters.\nentity<|#|>The Device<|#|>equipment<|#|>The Device is central to the story, with potential game-changing implications, and is revered by Taylor.\nrelation<|#|>Alex<|#|>Taylor<|#|>power dynamics, observation<|#|>Alex observes Taylor's authoritarian behavior and notes changes in Taylor's attitude toward the device.\nrelation<|#|>Alex<|#|>Jordan<|#|>shared goals, rebellion<|#|>Alex and Jordan share a commitment to discovery, which contrasts with Cruz's vision.)\nrelation<|#|>Taylor<|#|>Jordan<|#|>conflict resolution, mutual respect<|#|>Taylor and Jordan interact directly regarding the device, leading to a moment of mutual respect and an uneasy truce.\nrelation<|#|>Jordan<|#|>Cruz<|#|>ideological conflict, rebellion<|#|>Jordan's commitment to discovery is in rebellion against Cruz's vision of control and order.\nrelation<|#|>Taylor<|#|>The Device<|#|>reverence, technological significance<|#|>Taylor shows reverence towards the device, indicating its importance and potential impact.\n<|COMPLETE|>\n\n\n<Entity_types>\n[\"Person\",\"Creature\",\"Organization\",\"Location\",\"Event\",\"Concept\",\"Method\",\"Content\",\"Data\",\"Artifact\",\"NaturalObject\"]\n\n<Input Text>\n```\nStock markets faced a sharp downturn today as tech giants saw significant declines, with the global tech index dropping by 3.4% in midday trading. Analysts attribute the selloff to investor concerns over rising interest rates and regulatory uncertainty.\n\nAmong the hardest hit, nexon technologies saw its stock plummet by 7.8% after reporting lower-than-expected quarterly earnings. In contrast, Omega Energy posted a modest 2.1% gain, driven by rising oil prices.\n\nMeanwhile, commodity markets reflected a mixed sentiment. Gold futures rose by 1.5%, reaching $2,080 per ounce, as investors sought safe-haven assets. Crude oil prices continued their rally, climbing to $87.60 per barrel, supported by supply constraints and strong demand.\n\nFinancial experts are closely watching the Federal Reserve's next move, as speculation grows over potential rate hikes. The upcoming policy announcement is expected to influence investor confidence and overall market stability.\n```\n\n<Output>\nentity<|#|>Global Tech Index<|#|>category<|#|>The Global Tech Index tracks the performance of major technology stocks and experienced a 3.4% decline today.\nentity<|#|>Nexon Technologies<|#|>organization<|#|>Nexon Technologies is a tech company that saw its stock decline by 7.8% after disappointing earnings.\nentity<|#|>Omega Energy<|#|>organization<|#|>Omega Energy is an energy company that gained 2.1% in stock value due to rising oil prices.\nentity<|#|>Gold Futures<|#|>product<|#|>Gold futures rose by 1.5%, indicating increased investor interest in safe-haven assets.\nentity<|#|>Crude Oil<|#|>product<|#|>Crude oil prices rose to $87.60 per barrel due to supply constraints and strong demand.\nentity<|#|>Market Selloff<|#|>category<|#|>Market selloff refers to the significant decline in stock values due to investor concerns over interest rates and regulations.\nentity<|#|>Federal Reserve Policy Announcement<|#|>category<|#|>The Federal Reserve's upcoming policy announcement is expected to impact investor confidence and market stability.\nentity<|#|>3.4% Decline<|#|>category<|#|>The Global Tech Index experienced a 3.4% decline in midday trading.\nrelation<|#|>Global Tech Index<|#|>Market Selloff<|#|>market performance, investor sentiment<|#|>The decline in the Global Tech Index is part of the broader market selloff driven by investor concerns.\nrelation<|#|>Nexon Technologies<|#|>Global Tech Index<|#|>company impact, index movement<|#|>Nexon Technologies' stock decline contributed to the overall drop in the Global Tech Index.\nrelation<|#|>Gold Futures<|#|>Market Selloff<|#|>market reaction, safe-haven investment<|#|>Gold prices rose as investors sought safe-haven assets during the market selloff.\nrelation<|#|>Federal Reserve Policy Announcement<|#|>Market Selloff<|#|>interest rate impact, financial regulation<|#|>Speculation over Federal Reserve policy changes contributed to market volatility and investor selloff.\n<|COMPLETE|>\n\n\n<Entity_types>\n[\"Person\",\"Creature\",\"Organization\",\"Location\",\"Event\",\"Concept\",\"Method\",\"Content\",\"Data\",\"Artifact\",\"NaturalObject\"]\n\n<Input Text>\n```\nAt the World Athletics Championship in Tokyo, Noah Carter broke the 100m sprint record using cutting-edge carbon-fiber spikes.\n```\n\n<Output>\nentity<|#|>World Athletics Championship<|#|>event<|#|>The World Athletics Championship is a global sports competition featuring top athletes in track and field.\nentity<|#|>Tokyo<|#|>location<|#|>Tokyo is the host city of the World Athletics Championship.\nentity<|#|>Noah Carter<|#|>person<|#|>Noah Carter is a sprinter who set a new record in the 100m sprint at the World Athletics Championship.\nentity<|#|>100m Sprint Record<|#|>category<|#|>The 100m sprint record is a benchmark in athletics, recently broken by Noah Carter.\nentity<|#|>Carbon-Fiber Spikes<|#|>equipment<|#|>Carbon-fiber spikes are advanced sprinting shoes that provide enhanced speed and traction.\nentity<|#|>World Athletics Federation<|#|>organization<|#|>The World Athletics Federation is the governing body overseeing the World Athletics Championship and record validations.\nrelation<|#|>World Athletics Championship<|#|>Tokyo<|#|>event location, international competition<|#|>The World Athletics Championship is being hosted in Tokyo.\nrelation<|#|>Noah Carter<|#|>100m Sprint Record<|#|>athlete achievement, record-breaking<|#|>Noah Carter set a new 100m sprint record at the championship.\nrelation<|#|>Noah Carter<|#|>Carbon-Fiber Spikes<|#|>athletic equipment, performance boost<|#|>Noah Carter used carbon-fiber spikes to enhance performance during the race.\nrelation<|#|>Noah Carter<|#|>World Athletics Championship<|#|>athlete participation, competition<|#|>Noah Carter is competing at the World Athletics Championship.\n<|COMPLETE|>\n[{\"role\": \"user\", \"content\": \"---Task---\\nExtract entities and relationships from the input text in Data to be Processed below.\\n\\n---Instructions---\\n1.  **Strict Adherence to Format:** Strictly adhere to all format requirements for entity and relationship lists, including output order, field delimiters, and proper noun handling, as specified in the system prompt.\\n2.  **Output Content Only:** Output *only* the extracted list of entities and relationships. Do not include any introductory or concluding remarks, explanations, or additional text before or after the list.\\n3.  **Completion Signal:** Output `<|COMPLETE|>` as the final line after all relevant entities and relationships have been extracted and presented.\\n4.  **Output Language:** Ensure the output language is English. Proper nouns (e.g., personal names, place names, organization names) must be kept in their original language and not translated.\\n\\n---Data to be Processed---\\n<Entity_types>\\n[Person,Creature,Organization,Location,Event,Concept,Method,Content,Data,Artifact,NaturalObject]\\n\\n<Input Text>\\n```\\n# Harshit B. — Portfolio\\n\\n## About\\n\\nHarshit B. is an AI Engineer and ML Systems builder based in Boston, MA. He is pursuing a Master of Science in Data Analytics Engineering at Northeastern University (GPA: 3.9/4.0, expected December 2026). He holds a Bachelor of Engineering in Computer Engineering from LDRP Institute of Technology and Research, Gandhinagar, India (GPA: 3.3/4.0, May 2024).\\n\\nHe builds production ML systems — agentic AI platforms, temporal risk models, real-time voice agents, and scalable data pipelines. He cares about systems that work at scale, not just in notebooks.\\n\\nContact: brahmbhatt.h@northeastern.edu | 857-565-4643 | Boston, MA | LinkedIn: linkedin.com/in/harshitb1611\\n\\n## Certifications\\n\\n- Stanford Machine Learning\\n- DeepLearning.AI Generative AI\\n- UPenn Quantitative Modeling\\n\\n---\\n\\n## Work Experience\\n\\n### AI Engineer Intern — Staples Inc. (Jan 2026 – Present, Framingham, MA)\\n\\n- Spearheaded production-grade LLM applications automating high-labor workflows, reducing manual effort by 40% and error rates across enterprise retail operations.\\n- Constructed LangGraph-based inference pipelines with FastAPI, GraphQL, and gRPC integrations for real-time reasoning and retrieval over PGVector and Neo4j.\\n- Integrated OpenAI, Anthropic, Ollama, and vLLM backends through unified connector APIs, enabling rapid experimentation and model portability.\\n- Optimized Kubernetes-deployed vLLM clusters for low latency and high throughput via dynamic batching, quantization, and GPU utilization tuning.\\n\\n### ML Engineer Intern — Pixeltechnologies (Jan – Jul 2024, Remote)\\n\\n- Architected Python-based prediction pipelines using scikit-learn and XGBoost to forecast ad engagement on 100K+ events; enhanced campaign ROI by 22%.\\n- Engineered SQL-driven ETL and Airflow DAGs to process high-velocity A/B test logs; cut model retraining latency by 40%.\\n- Operationalized ML explainability by deploying interpretable models with SHAP values; uncovered 3 key vulnerabilities and improved accuracy by 18%.\\n\\n### Data Analyst Intern — GROWITUP (Jul 2023 – Jan 2024, Remote)\\n\\n- Pioneered a vectorized search system using OpenAI embeddings and FastAPI, achieving 96% faster retrieval across 5K+ documents.\\n- Modeled user sessions with Snowflake and PostgreSQL to detect behavioral anomalies and data drift patterns.\\n\\n---\\n\\n## Projects\\n\\n### FrontShiftAI: Multi-Tenant Agentic Platform (Sept 2025)\\nTechnologies: FastAPI, Airflow, ChromaDB, Modal, LiveKit, React\\n\\n- Designed a Unified Agent Router in FastAPI using regex-based intent detection with LLM fallback to intelligently route requests between deterministic SQL agents and probabilistic LLaMA-3 RAG pipelines.\\n- Automated Airflow 3.0 ETL pipelines utilizing a dedicated SmolVLM Vision Microservice to ingest unstructured PDF data, validating quality via Great Expectations before embedding into vector databases.\\n- Implemented Hybrid Search (BM25 + Vector) with Cross-Encoder Reranking, significantly reducing hallucination rates for policy queries.\\n- Deployed a serverless voice agent on Modal via LiveKit WebRTC for bi-directional real-time audio interactions.\\n\\n### Credit Risk Forecasting via Temporal Architectures (Apr 2025)\\nTechnologies: TensorFlow, SHAP, Azure CI/CD, SQL\\n\\n- Segmented 30K+ financial transactions into lag-aware bins and extracted temporal features to surface default patterns.\\n- Trained Bi-LSTM and TabTransformer models for risk classification; boosted minority F1-score by 16% achieving 81.9% accuracy.\\n- Visualized temporal risk triggers using SHAP plots to improve auditor interpretability and model trust.\\n- Azure DevOps CI/CD pipelines for reproducible deployment.\\n\\n### GEMTREK: Diamond Manufacturing Analytics System (Dec 2024)\\nTechnologies: SQL, Python, Power BI, Snowflake, Azure\\n\\n- Optimized Snowflake ETL pipelines (35% faster processing).\\n- Python analytics on 100K+ records for diamond manufacturing operations.\\n- Real-time Power BI dashboards via REST API — 40% better operational transparency.\\n\\n---\\n\\n## Technical Skills\\n\\n- **Languages:** Python, C++, SQL, Shell Scripting, JavaScript\\n- **AI/ML/DL:** Scikit-learn, XGBoost, TensorFlow, PyTorch, Hugging Face, SHAP, Model Training & Fine-Tuning\\n- **LLM & Gen AI:** OpenAI API, LangChain, LangGraph, vLLM, RAG Pipelines, Agentic Frameworks, Tool-Calling\\n- **Vector Databases:** ChromaDB, Pinecone, PGVector, Neo4j, Hybrid Search (BM25 + Vector)\\n- **Data Pipelines & MLOps:** Apache Airflow, FastAPI, Docker, Kubernetes, CI/CD (Azure, GitHub), Model Monitoring\\n- **Cloud & Infrastructure:** GCP (GKE, Cloud SQL), AWS S3, Snowflake, PostgreSQL, Azure Databricks\\n```\\n\\n<Output>\"}, {\"role\": \"assistant\", \"content\": \"entity<|#|>Harshit B.<|#|>Person<|#|>Harshit B. is an AI Engineer and ML Systems builder based in Boston, MA, with a Master of Science in Data Analytics Engineering from Northeastern University.\\nentity<|#|>Northeastern University<|#|>Organization<|#|>Northeastern University is an educational institution where Harshit B. is pursuing his Master of Science in Data Analytics Engineering.\\nentity<|#|>LDRP Institute of Technology and Research<|#|>Organization<|#|>LDRP Institute of Technology and Research is an educational institution in Gandhinagar, India, where Harshit B. earned his Bachelor of Engineering in Computer Engineering.\\nentity<|#|>Boston<|#|>Location<|#|>Boston is the city where Harshit B. is based.\\nentity<|#|>Staples Inc.<|#|>Organization<|#|>Staples Inc. is a company where Harshit B. worked as an AI Engineer Intern.\\nentity<|#|>Pixeltechnologies<|#|>Organization<|#|>Pixeltechnologies is a company where Harshit B. worked as an ML Engineer Intern.\\nentity<|#|>GROWITUP<|#|>Organization<|#|>GROWITUP is a company where Harshit B. worked as a Data Analyst Intern.\\nentity<|#|>FrontShiftAI<|#|>Artifact<|#|>FrontShiftAI is a multi-tenant agentic platform developed by Harshit B.\\nentity<|#|>Credit Risk Forecasting via Temporal Architectures<|#|>Artifact<|#|>Credit Risk Forecasting via Temporal Architectures is a project developed by Harshit B. for credit risk forecasting.\\nentity<|#|>GEMTREK<|#|>Artifact<|#|>GEMTREK is a diamond manufacturing analytics system developed by Harshit B.\\nentity<|#|>FastAPI<|#|>Artifact<|#|>FastAPI is a technology used by Harshit B. in his projects.\\nentity<|#|>Airflow<|#|>Artifact<|#|>Airflow is a technology used by Harshit B. in his projects.\\nentity<|#|>ChromaDB<|#|>Artifact<|#|>ChromaDB is a vector database used by Harshit B. in his projects.\\nentity<|#|>Modal<|#|>Artifact<|#|>Modal is a technology used by Harshit B. in his projects.\\nentity<|#|>LiveKit<|#|>Artifact<|#|>LiveKit is a technology used by Harshit B. in his projects.\\nentity<|#|>React<|#|>Artifact<|#|>React is a technology used by Harshit B. in his projects.\\nentity<|#|>TensorFlow<|#|>Artifact<|#|>TensorFlow is a technology used by Harshit B. in his projects.\\nentity<|#|>SHAP<|#|>Artifact<|#|>SHAP is a technology used by Harshit B. in his projects.\\nentity<|#|>Azure<|#|>Artifact<|#|>Azure is a cloud platform used by Harshit B. in his projects.\\nentity<|#|>SQL<|#|>Artifact<|#|>SQL is a language used by Harshit B. in his projects.\\nentity<|#|>Python<|#|>Artifact<|#|>Python is a language used by Harshit B. in his projects.\\nrelation<|#|>Harshit B.<|#|>Northeastern University<|#|>education, affiliation<|#|>Harshit B. is affiliated with Northeastern University as a student.\\nrelation<|#|>Harshit B.<|#|>Staples Inc.<|#|>work experience, AI engineering<|#|>Harshit B. worked as an AI Engineer Intern at Staples Inc.\\nrelation<|#|>Harshit B.<|#|>Pixeltechnologies<|#|>work experience, ML engineering<|#|>Harshit B. worked as an ML Engineer Intern at Pixeltechnologies.\\nrelation<|#|>Harshit B.<|#|>GROWITUP<|#|>work experience, data analysis<|#|>Harshit B. worked as a Data Analyst Intern at GROWITUP.\\nrelation<|#|>Harshit B.<|#|>FrontShiftAI<|#|>project development, AI engineering<|#|>Harshit B. developed the FrontShiftAI project.\\nrelation<|#|>Harshit B.<|#|>Credit Risk Forecasting via Temporal Architectures<|#|>project development, credit risk forecasting<|#|>Harshit B. developed the Credit Risk Forecasting via Temporal Architectures project.\\nrelation<|#|>Harshit B.<|#|>GEMTREK<|#|>project development, diamond manufacturing analytics<|#|>Harshit B. developed the GEMTREK project.\\nrelation<|#|>FrontShiftAI<|#|>FastAPI<|#|>technology usage, project development<|#|>FrontShiftAI uses FastAPI as a technology.\\nrelation<|#|>FrontShiftAI<|#|>Airflow<|#|>technology usage, project development<|#|>FrontShiftAI uses Airflow as a technology.\\nrelation<|#|>Credit Risk Forecasting via Temporal Architectures<|#|>TensorFlow<|#|>technology usage, project development<|#|>Credit Risk Forecasting via Temporal Architectures uses TensorFlow as a technology.\\nrelation<|#|>GEMTREK<|#|>SQL<|#|>technology usage, project development<|#|>GEMTREK uses SQL as a technology.\\n<|COMPLETE|>\"}]",
    "queryparam": null,
    "create_time": 1771210916,
    "update_time": 1771210916,
    "_id": "default:extract:018f378f3de25ce83a9649cd088ef464"
  }
}